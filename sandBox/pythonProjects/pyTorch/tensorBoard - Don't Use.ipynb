{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ef5828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fedb8068610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# set display option for output\n",
    "torch.set_printoptions(linewidth = 120)\n",
    "# on by default\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "054f3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST'\n",
    "    ,train = True\n",
    "    ,download = True\n",
    "    ,transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f8f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1765b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network class\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        # conv layers\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "        # fc, lin, dense layers\n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features = 60, out_features = 10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # layer 1\n",
    "        t = t\n",
    "        \n",
    "        # layer 2\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        # layer 3\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        # layer 4\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # layer 5\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # output\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return(t)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c5343fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1000 True\n",
      "0.01 1000 False\n",
      "0.01 10000 True\n",
      "0.01 10000 False\n",
      "0.001 1000 True\n",
      "0.001 1000 False\n",
      "0.001 10000 True\n",
      "0.001 10000 False\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "parameters = dict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [1000, 10000],\n",
    "    shuffle = [True, False]\n",
    ")\n",
    "\n",
    "param_values = [v for v in parameters.values()]\n",
    "\n",
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    print(lr, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97c6cd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 total_correct:  37813 loss:  57555.59951066971\n",
      "epoch:  1 total_correct:  48533 loss:  30179.37308549881\n",
      "epoch:  2 total_correct:  50917 loss:  24442.48142838478\n",
      "epoch:  0 total_correct:  37330 loss:  58796.29546403885\n",
      "epoch:  1 total_correct:  47622 loss:  32171.751022338867\n",
      "epoch:  2 total_correct:  49829 loss:  27324.55202937126\n",
      "epoch:  0 total_correct:  13320 loss:  126625.98013877869\n",
      "epoch:  1 total_correct:  29485 loss:  82211.23814582825\n",
      "epoch:  2 total_correct:  36499 loss:  61504.396200180054\n",
      "epoch:  0 total_correct:  11535 loss:  129398.63801002502\n",
      "epoch:  1 total_correct:  29733 loss:  79265.78044891357\n",
      "epoch:  2 total_correct:  38784 loss:  56915.616393089294\n",
      "epoch:  0 total_correct:  26772 loss:  99195.48845291138\n",
      "epoch:  1 total_correct:  42492 loss:  45866.133987903595\n",
      "epoch:  2 total_correct:  45106 loss:  38869.5964217186\n",
      "epoch:  0 total_correct:  28324 loss:  98757.77024030685\n",
      "epoch:  1 total_correct:  43052 loss:  44722.99253940582\n",
      "epoch:  2 total_correct:  45176 loss:  38774.469673633575\n",
      "epoch:  0 total_correct:  6127 loss:  138032.32192993164\n",
      "epoch:  1 total_correct:  11307 loss:  137096.91524505615\n",
      "epoch:  2 total_correct:  17449 loss:  134158.20360183716\n",
      "epoch:  0 total_correct:  7960 loss:  137827.6777267456\n",
      "epoch:  1 total_correct:  16326 loss:  135839.87712860107\n",
      "epoch:  2 total_correct:  20008 loss:  130342.60272979736\n"
     ]
    }
   ],
   "source": [
    "#network = Network()\n",
    "# batch_size = 100\n",
    "# lr = 0.01\n",
    "\n",
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    network = Network()\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "    optimizer = optim.Adam(network.parameters(), lr = lr)\n",
    "\n",
    "    images, labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_graph(network, images)\n",
    "\n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            # pass a batch\n",
    "            preds = network(images)\n",
    "            # calculate the loss\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "            # zero out accumulated gradient\n",
    "            optimizer.zero_grad()\n",
    "            # calculate new gradients\n",
    "            loss.backward()\n",
    "            # update network weights\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()*batch_size\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        tb.add_scalar('Loss', total_loss, epoch)\n",
    "        tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "        for name, weight in network.named_parameters():\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "        print('epoch: ', epoch, 'total_correct: ', total_correct, 'loss: ', total_loss)\n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d1bd66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0038, -0.0005,  0.0116, -0.0370, -0.0551],\n",
       "          [-0.0045,  0.0013,  0.0055, -0.0415, -0.0411],\n",
       "          [-0.0069,  0.0039,  0.0014, -0.0296, -0.0335],\n",
       "          [ 0.0036,  0.0216,  0.0053, -0.0341, -0.0507],\n",
       "          [ 0.0130,  0.0154, -0.0206, -0.0401, -0.0630]]],\n",
       "\n",
       "\n",
       "        [[[-0.0494, -0.0115, -0.0771, -0.0641, -0.1180],\n",
       "          [-0.0804, -0.0403, -0.0810, -0.0662, -0.1259],\n",
       "          [-0.0976, -0.0296, -0.0930, -0.0598, -0.0854],\n",
       "          [-0.1145, -0.0317, -0.0703, -0.0404, -0.0375],\n",
       "          [-0.1028, -0.0368, -0.0813, -0.0516, -0.0460]]],\n",
       "\n",
       "\n",
       "        [[[-0.0019, -0.0196,  0.0275,  0.0236, -0.0215],\n",
       "          [ 0.0008,  0.0089,  0.0207,  0.0479, -0.0037],\n",
       "          [-0.0067, -0.0024,  0.0134,  0.0423,  0.0285],\n",
       "          [-0.0107,  0.0114,  0.0205,  0.0293,  0.0373],\n",
       "          [ 0.0175,  0.0135,  0.0289,  0.0433,  0.0479]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1908,  0.2078,  0.1680,  0.1956,  0.2211],\n",
       "          [ 0.1655,  0.1617,  0.1361,  0.1624,  0.2028],\n",
       "          [ 0.1486,  0.1502,  0.1239,  0.1166,  0.1545],\n",
       "          [ 0.1388,  0.1203,  0.1229,  0.1002,  0.1423],\n",
       "          [ 0.1465,  0.1359,  0.1247,  0.1026,  0.1442]]],\n",
       "\n",
       "\n",
       "        [[[-0.0022, -0.0007, -0.0026,  0.0231,  0.0164],\n",
       "          [-0.0028, -0.0023,  0.0054,  0.0261,  0.0116],\n",
       "          [-0.0024,  0.0023,  0.0145,  0.0192,  0.0190],\n",
       "          [ 0.0105, -0.0174,  0.0067,  0.0092,  0.0072],\n",
       "          [ 0.0150, -0.0162,  0.0068, -0.0026, -0.0036]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0307,  0.0340,  0.0267, -0.0125, -0.0003],\n",
       "          [ 0.0466,  0.0415,  0.0310, -0.0038,  0.0065],\n",
       "          [ 0.0203,  0.0271,  0.0177, -0.0084,  0.0176],\n",
       "          [ 0.0218,  0.0423,  0.0332,  0.0065,  0.0229],\n",
       "          [ 0.0349,  0.0565,  0.0517,  0.0235,  0.0369]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36eb22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter()\n",
    "\n",
    "network = Network()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62aac71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will not work unless you have updated your gradients !!!! weight.grad will return None\n",
    "tb.add_scalar('Loss', total_loss, epoch)\n",
    "tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a900704f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Got <class 'NoneType'>, but numpy array, torch tensor, or caffe2 blob name are expected.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n2/n18flxbj1qz3xh362rsc19240000gn/T/ipykernel_9139/1274119280.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;34m'conv1.weight.grad'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;34m,\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         )\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorFlow/lib/python3.7/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_histogram\u001b[0;34m(self, tag, values, global_step, bins, walltime, max_bins)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         self._get_file_writer().add_summary(\n\u001b[0;32m--> 430\u001b[0;31m             histogram(tag, values, bins, max_bins=max_bins), global_step, walltime)\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     def add_histogram_raw(self, tag, min, max, num, sum, sum_squares,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorFlow/lib/python3.7/site-packages/torch/utils/tensorboard/summary.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(name, values, bins, max_bins)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorFlow/lib/python3.7/site-packages/torch/utils/tensorboard/_convert_np.py\u001b[0m in \u001b[0;36mmake_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_prepare_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     raise NotImplementedError(\n\u001b[0;32m---> 26\u001b[0;31m         'Got {}, but numpy array, torch tensor, or caffe2 blob name are expected.'.format(type(x)))\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Got <class 'NoneType'>, but numpy array, torch tensor, or caffe2 blob name are expected."
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader: # Get Batch\n",
    "\n",
    "        # Pass Batch\n",
    "        # Calculate Loss\n",
    "        # Calculate Gradient\n",
    "        # Update Weights\n",
    "\n",
    "        tb.add_scalar('Loss', total_loss, epoch)\n",
    "        tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "        tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "        tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "        tb.add_histogram(\n",
    "            'conv1.weight.grad'\n",
    "            ,network.conv1.weight.grad\n",
    "            ,epoch\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"epoch\", epoch, \n",
    "            \"total_correct:\", total_correct, \n",
    "            \"loss:\", total_loss\n",
    "        )\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9a285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
